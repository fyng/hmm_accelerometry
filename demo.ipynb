{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "from hmm import HMM\n",
    "import re\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define useful functions\n",
    "def extract_prefix(text, pattern):\n",
    "    match = re.match(pattern, text)\n",
    "    if match:\n",
    "        # If the first group (beat\\d+_) is matched, use it; otherwise, use the second group\n",
    "        prefix = match.group(1) if match.group(1) else match.group(2)\n",
    "        return prefix\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "def quantization_model(data, n_clusters):\n",
    "    X_all = []\n",
    "    for v in data.values():\n",
    "        X_all.extend(v)\n",
    "    x_all = np.concatenate(X_all, axis=0)\n",
    "    x_all = x_all[:,1:] # remove time column\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=0, n_init=\"auto\").fit(x_all)\n",
    "\n",
    "    return kmeans\n",
    "\n",
    "def train_model(data, key, n_clusters, n_hidden_states, q_model):\n",
    "    X = np.concatenate(data[key], axis=0)\n",
    "    X = X[:,1:] # remove time column\n",
    "\n",
    "    y = q_model.predict(X)\n",
    "\n",
    "    model = HMM(n_hidden=n_hidden_states, n_obs=n_clusters, verbose=False)\n",
    "    loss = model.fit(y)\n",
    "    model.save(filepath=f'pretrained_models/hmm_{key}.json')\n",
    "\n",
    "    plt.plot(y)\n",
    "    plt.savefig(f'plots/quantized_{key}.png')\n",
    "    plt.clf()\n",
    "    \n",
    "    plt.plot(-np.array(loss))\n",
    "    plt.savefig(f'plots/logloss_{key}.png')\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data contains six different motions: Wave, Infinity, Eight, Circle, Beat3, Beat4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "train_dir = 'data/train'\n",
    "\n",
    "pattern = r\"^(beat\\d+)|([^\\d]+)\"\n",
    "\n",
    "files = os.listdir(train_dir)\n",
    "for fn in files:\n",
    "    type = extract_prefix(fn, pattern)\n",
    "    x = np.loadtxt(os.path.join(train_dir, fn))\n",
    "    if type not in data:\n",
    "        data[type] = [x]\n",
    "    else:\n",
    "        data[type].append(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ts , Wx, Wy, Wz, Ax, Ay, Az\n",
    "(Time (millisecond), 3x Gyroscope (rad/sec), 3x Accelerometer (m/s2) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train models\n",
    "n_clusters = 50\n",
    "n_hidden_states = 10\n",
    "\n",
    "q_model = quantization_model(data, n_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(q_model, open('pretrained_models/kmeans_50.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for key in data.keys():\n",
    "    train_model(data, key, n_clusters, n_hidden_states, q_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: update directory to the appropriate test file\n",
    "test_dir = 'data/val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pretrained_models/kmeans_50.pkl\", \"rb\") as f:\n",
    "    q_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'pretrained_models/'\n",
    "model_name = ['hmm_beat3', 'hmm_beat4', 'hmm_circle', 'hmm_eight', 'hmm_inf', 'hmm_wave']  \n",
    "results = {}\n",
    "\n",
    "pattern = r\"^(beat\\d+)|([^\\d]+)\"\n",
    "files = os.listdir(test_dir)\n",
    "for fn in files:\n",
    "    log_loss = []\n",
    "    type = extract_prefix(fn, pattern)\n",
    "    x = np.loadtxt(os.path.join(test_dir, fn))\n",
    "    x = x[:,1:] # remove time column\n",
    "\n",
    "    y = q_model.predict(x)\n",
    "    for m in model_name:\n",
    "        model = HMM(n_hidden=n_hidden_states, n_obs=n_clusters, verbose=False)\n",
    "        model.load(filepath=f'{model_path}{m}.json')\n",
    "        log_loss.append(model.predict(y))\n",
    "                        \n",
    "    results[fn] = log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'circle31.txt': [-5570.778230347408,\n",
       "  -4034.2529190469036,\n",
       "  -266.95294916283655,\n",
       "  -11568.187821202006,\n",
       "  -11568.187821202006,\n",
       "  -11568.187821202006],\n",
       " 'beat3_31.txt': [-749.2817548369553,\n",
       "  -921.0345745400232,\n",
       "  -12449.981424876627,\n",
       "  -7109.6727791937665,\n",
       "  -11451.808963923431,\n",
       "  -6352.691317430477],\n",
       " 'inf31.txt': [-6950.617999659129,\n",
       "  -8554.63179049122,\n",
       "  -14663.080375151883,\n",
       "  -4067.0538031143165,\n",
       "  -490.22800139279667,\n",
       "  -9352.333466865295],\n",
       " 'beat4_31.txt': [-1720.7516574551764,\n",
       "  -775.7216855536545,\n",
       "  -13550.998035732659,\n",
       "  -14018.925284817647,\n",
       "  -6549.664136303634,\n",
       "  -7400.683331013022],\n",
       " 'eight31.txt': [-7483.572796925468,\n",
       "  -7831.512305257039,\n",
       "  -10978.726021395534,\n",
       "  -792.7728915528071,\n",
       "  -3578.3804842837285,\n",
       "  -6481.384839868422]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "circle31.txt: hmm_circle\n",
      "beat3_31.txt: hmm_beat3\n",
      "inf31.txt: hmm_inf\n",
      "beat4_31.txt: hmm_beat4\n",
      "eight31.txt: hmm_eight\n"
     ]
    }
   ],
   "source": [
    "# report top scoring model for each test file\n",
    "for k,v in results.items():\n",
    "    print(f'{k}: {model_name[np.argmax(v)]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
