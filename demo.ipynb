{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "from hmm import HMM\n",
    "import re\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define useful functions\n",
    "def extract_prefix(text, pattern):\n",
    "    match = re.match(pattern, text)\n",
    "    if match:\n",
    "        # If the first group (beat\\d+_) is matched, use it; otherwise, use the second group\n",
    "        prefix = match.group(1) if match.group(1) else match.group(2)\n",
    "        return prefix\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "def quantization_model(data, n_clusters):\n",
    "    X_all = []\n",
    "    for v in data.values():\n",
    "        X_all.extend(v)\n",
    "    x_all = np.concatenate(X_all, axis=0)\n",
    "    x_all = x_all[:,1:] # remove time column\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=0, n_init=\"auto\").fit(x_all)\n",
    "\n",
    "    return kmeans\n",
    "\n",
    "def train_model(data, key, n_clusters, n_hidden_states, q_model):\n",
    "    X = np.concatenate(data[key], axis=0)\n",
    "    X = X[:,1:] # remove time column\n",
    "\n",
    "    y = q_model.predict(X)\n",
    "\n",
    "    model = HMM(n_hidden=n_hidden_states, n_obs=n_clusters, verbose=False)\n",
    "    loss = model.fit(y)\n",
    "    model.save(filepath=f'pretrained_models/hmm_{key}.json')\n",
    "\n",
    "    plt.plot(y)\n",
    "    plt.savefig(f'plots/quantized_{key}.png')\n",
    "    plt.clf()\n",
    "    \n",
    "    plt.plot(-np.array(loss))\n",
    "    plt.savefig(f'plots/logloss_{key}.png')\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 50\n",
    "n_hidden_states = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data contains six different motions: Wave, Infinity, Eight, Circle, Beat3, Beat4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "train_dir = 'data/train'\n",
    "\n",
    "pattern = r\"^(beat\\d+)|([^\\d]+)\"\n",
    "\n",
    "files = os.listdir(train_dir)\n",
    "for fn in files:\n",
    "    type = extract_prefix(fn, pattern)\n",
    "    x = np.loadtxt(os.path.join(train_dir, fn))\n",
    "    if type not in data:\n",
    "        data[type] = [x]\n",
    "    else:\n",
    "        data[type].append(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ts , Wx, Wy, Wz, Ax, Ay, Az\n",
    "(Time (millisecond), 3x Gyroscope (rad/sec), 3x Accelerometer (m/s2) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train models\n",
    "n_clusters = 50\n",
    "n_hidden_states = 10\n",
    "\n",
    "q_model = quantization_model(data, n_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(q_model, open('pretrained_models/kmeans_50.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for key in data.keys():\n",
    "    train_model(data, key, n_clusters, n_hidden_states, q_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: update directory to the appropriate test file\n",
    "test_dir = 'data/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pretrained_models/kmeans_50.pkl\", \"rb\") as f:\n",
    "    q_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'pretrained_models/'\n",
    "model_name = ['hmm_beat3', 'hmm_beat4', 'hmm_circle', 'hmm_eight', 'hmm_inf', 'hmm_wave']  \n",
    "motion_name = ['beat3', 'beat4', 'circle', 'eight', 'inf', 'wave']  \n",
    "results = {}\n",
    "\n",
    "pattern = r\"^(beat\\d+)|([^\\d]+)\"\n",
    "files = os.listdir(test_dir)\n",
    "for fn in files:\n",
    "    log_loss = []\n",
    "    type = extract_prefix(fn, pattern)\n",
    "    x = np.loadtxt(os.path.join(test_dir, fn))\n",
    "    x = x[:,1:] # remove time column\n",
    "\n",
    "    y = q_model.predict(x)\n",
    "    for m in model_name:\n",
    "        model = HMM(n_hidden=n_hidden_states, n_obs=n_clusters, verbose=False)\n",
    "        model.load(filepath=f'{model_path}{m}.json')\n",
    "        log_loss.append(model.predict(y))\n",
    "                        \n",
    "    results[fn] = log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test7.txt: \n",
      " top-1: wave \n",
      " top-3: ['wave', 'eight', 'beat3']\n",
      "test6.txt: \n",
      " top-1: eight \n",
      " top-3: ['eight', 'inf', 'wave']\n",
      "test4.txt: \n",
      " top-1: beat4 \n",
      " top-3: ['beat4', 'beat3', 'wave']\n",
      "test5.txt: \n",
      " top-1: circle \n",
      " top-3: ['circle', 'beat4', 'beat3']\n",
      "test1.txt: \n",
      " top-1: inf \n",
      " top-3: ['inf', 'eight', 'beat3']\n",
      "test2.txt: \n",
      " top-1: beat4 \n",
      " top-3: ['beat4', 'beat3', 'inf']\n",
      "test3.txt: \n",
      " top-1: inf \n",
      " top-3: ['inf', 'eight', 'beat3']\n",
      "test8.txt: \n",
      " top-1: beat4 \n",
      " top-3: ['beat4', 'beat3', 'wave']\n"
     ]
    }
   ],
   "source": [
    "# report top scoring model for each test file\n",
    "for k,v in results.items():\n",
    "    indices_desc = np.argsort(v)[::-1]\n",
    "    print(f'{k}: \\n top-1: {motion_name[np.argmax(v)]} \\n top-3: {[motion_name[i] for i in indices_desc[:3]]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
